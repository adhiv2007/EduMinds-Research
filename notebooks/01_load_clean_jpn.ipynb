{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6263b076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading student data...\n",
      "Loading school data...\n",
      "Merging student + school data...\n",
      "\n",
      "Top 20 variables by % missing (Japan):\n",
      "REPEAT          100.0\n",
      "BSMJ             22.2\n",
      "DURECEC          20.6\n",
      "PERCOOP           4.2\n",
      "BEINGBULLIED      3.2\n",
      "PERCOMP           3.1\n",
      "METASUM           3.0\n",
      "METASPAM          3.0\n",
      "UNDREM            2.8\n",
      "EMOSUPS           2.4\n",
      "BELONG            1.9\n",
      "EUDMO             1.9\n",
      "MASTGOAL          1.8\n",
      "WORKMAST          1.8\n",
      "SCREADCOMP        1.7\n",
      "GFOFAIL           1.7\n",
      "RESILIENCE        1.6\n",
      "ADAPTIVITY        1.5\n",
      "PERFEED           1.5\n",
      "SCREADDIFF        1.5\n",
      "dtype: float64\n",
      "\n",
      "Saved cleaned Japan data → ..\\data\\processed\\japan_clean.pkl (rows: 6109)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import pyreadstat\n",
    "\n",
    "STU_PATH = Path(\"../data/raw/Student Data.sav\") #path to the student data file\n",
    "SCH_PATH = Path(\"../data/raw/School Data.sav\") #path to the school data file\n",
    "\n",
    "PREDICTORS = [\n",
    "    #Individual-level Predictors\n",
    "    \"ST004D01T\", #Gender\n",
    "    \"AGE\", #Age\n",
    "    \"GRADE\", #Grade\n",
    "    \"BSMJ\", #Expected Occupational Status\n",
    "    \"JOYREAD\", #Joy of Reading\n",
    "    \"SCREADCOMP\", #Reading Self-Concept: Competence\n",
    "    \"SCREADDIFF\", #Reading Self-Concept: Difficulty\n",
    "    \"COMPETE\", #Competitiveness\n",
    "    \"WORKMAST\", #Work Mastery Orientation\n",
    "    \"GFOFAIL\", # General Fear of Failure\n",
    "    \"EUDMO\", #Sense of Meaning in Life (Eudaimonia)  \n",
    "    \"RESILIENCE\", #Resilience\n",
    "    \"MASTGOAL\", #Mastery Goal Orientation\n",
    "\n",
    "    #Proximal-level Predictors\n",
    "    \"REPEAT\", #Grade Repetition History\n",
    "    \"UNDREM\", #Meta-cognition: Understanding & Remembering \n",
    "    \"METASUM\", #Meta-cognition: Summarizing\n",
    "    \"METASPAM\", #Meta-cognition: Assessing Credibility\n",
    "\n",
    "    #Microsystem-Level Factors (Family, Peers, & School CLimate)\n",
    "    \"EMOSUPS\", #Parental Emotional Support\n",
    "    \"DURECEC\", #Duration in Early Childhood Education and Care\n",
    "    \"BELONG\", #School Belonging\n",
    "    \"PERCOMP\", #Perceived School Competitiveness \n",
    "    \"PERCOOP\", #Perceived School Cooperation\n",
    "    \"ATTLNACT\", #Attitudes Towards Learning Activities\n",
    "    \"DISCLIMA\", #Disciplinary Climate (Language Lessons)\n",
    "    \"TEACHSUP\", #Teacher Support (Language Lessons)\n",
    "    \"DIRINS\", #Teacher-Directed Instruction \n",
    "    \"PERFEED\", #Perceived Feedback from Teachers\n",
    "    \"STIMREAD\", #Teacher's Stimulation of Reading Engagement\n",
    "    \"ADAPTIVITY\", #Adapation of Instruction\n",
    "    \"TEACHINT\", #Perceived Teacher Interest \n",
    "\n",
    "    #Macrosystem/Exosystem-level Predictors\n",
    "    \"ESCS\", #Family Socioeconomic Status(Index)\n",
    "    \"EDUSHORT\", #Shortage of Educational Resources\n",
    "    \"RATCMP1\", #Number of Computers per Student\n",
    "    \"RATCMP2\", #Percentage of Computers Connected to the Internet\n",
    "]\n",
    "\n",
    "print(\"Loading student data...\")\n",
    "\n",
    "stu_df, _ = pyreadstat.read_sav(STU_PATH, apply_value_formats=False) #loads student data\n",
    "stu_df = stu_df[stu_df[\"CNT\"] == \"JPN\"] #filters for Japan data onlhy\n",
    "\n",
    "print(\"Loading school data...\")\n",
    "\n",
    "sch_df, _ = pyreadstat.read_sav(SCH_PATH, apply_value_formats=False) #loads school data\n",
    "sch_jpn = sch_df[sch_df[\"CNT\"] == \"JPN\"][[\"CNTSCHID\",\"RATCMP1\",\"RATCMP2\",\"EDUSHORT\"]] #filters for Japan data only \n",
    "\n",
    "print(\"Merging student + school data...\")\n",
    "\n",
    "df = stu_df.merge(sch_jpn, on = \"CNTSCHID\", how = \"left\") #merges student and school data\n",
    "\n",
    "DV = \"BEINGBULLIED\" #dependent variable of BeingBullied\n",
    "df = df[PREDICTORS + [DV, \"CNTSCHID\"]] #selects predictors and dependent variable\n",
    "\n",
    "missing = (df.isna().mean() * 100).sort_values(ascending=False) #calculates percentage of missing values for each variable\n",
    "print(\"\\nTop 20 variables by % missing (Japan):\") \n",
    "print(missing.head(20).round(1)) \n",
    "\n",
    "out_path = Path(\"../data/processed/japan_clean.pkl\") #path to save the cleaned data\n",
    "df.to_pickle(out_path)\n",
    "print(f\"\\nSaved cleaned Japan data → {out_path} (rows: {len(df)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5ff8419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved final cleaned Japan data → ..\\data\\processed\\japan_clean_final.pkl (shape: (6109, 34))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df = pd.read_pickle(\"../data/processed/japan_clean.pkl\") #loads the processed Japan data \n",
    "\n",
    "df = df.drop(columns = [\"REPEAT\"]) #drops the REPEAT column\n",
    "\n",
    "DV = \"BEINGBULLIED\" \n",
    "X = df.drop(columns = [DV, \"CNTSCHID\"]) #drop DV + School ID and has only features\n",
    "y = df[DV].copy() #copy the dependent variable\n",
    "\n",
    "X[\"ST004D01T\"] = X[\"ST004D01T\"].map({1:0, 2:1}) #maps male variable to 0 and female variable to 1\n",
    "\n",
    "num_cols = X.columns.tolist() #stores the names of all features \n",
    "\n",
    "imputer = SimpleImputer(strategy = \"median\")\n",
    "X_imputed = pd.DataFrame(imputer.fit_transform(X), columns = num_cols, index = X.index) #fills in missing values using the median of each column \n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X_imputed), columns = num_cols, index = X.index) #standardize the data so that mean = 0 and STD = 1\n",
    "\n",
    "jpn_final = X_scaled.copy() \n",
    "jpn_final[DV] = y.values #combines the scaled features with the dependent variable back into single dataframe\n",
    "\n",
    "out_final = Path(\"../data/processed/japan_clean_final.pkl\") #saves data to a new file \n",
    "jpn_final.to_pickle(out_final)\n",
    "print(f\"Saved final cleaned Japan data → {out_final} (shape: {jpn_final.shape})\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
